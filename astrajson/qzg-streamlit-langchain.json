{
    "key": "qzg-streamlit-langchain",
    "tags": [
        "vector",
        "langchain",
        "streamlit",
        "astradb",
        "localization",
        "rails"
    ],
    "urls": {
        "github": "https://github.com/qzg/streamlit-langchain",
        "heroimage": "https://raw.githubusercontent.com/qzg/streamlit-langchain/main/assets/QA-app-RAG.png"
    },
    "last_modified": "Thu, 25 Jan 2024 22:59:27 GMT",
    "forks_count": 64,
    "stargazers_count": 4,
    "name": "Configurable Enterprise Chat Agent",
    "description": "This Chat Agent is build specifically as a reusable and configurable sample app to share with enterprises or prospects.",
    "duration": "20 minutes",
    "skilllevel": "Intermediate",
    "priority": 1,
    "readme": "<h1>Configurable Enterprise Chat Agent</h1>\n<p>This Chat Agent is build specifically as a reusable and configurable sample app to share with enterprises or prospects.</p>\n<ol>\n<li>It uses <a href=\"https://www.langchain.com/\">LangChain</a> as the framework to easily set up LLM Q&amp;A chains</li>\n<li>It uses <a href=\"https://streamlit.io/\">Streamlit</a> as the framework to easily create Web Applications</li>\n<li>It uses <a href=\"https://astra.datastax.com/\">Astra DB</a> as the Vector Store to enable Rerieval Augmented Generation in order to provide meaningfull contextual interactions</li>\n<li>It uses <a href=\"https://astra.datastax.com/\">Astra DB</a> as Short Term Memory to keep track of what was said and generated</li>\n<li>It uses a StreamingCallbackHandler to stream output to the screen which prevents having to wait for the final answer</li>\n<li>It allows for new Content to be uploaded, Vectorized and Stored into the Astra DB Vector Database so it can be used as Context</li>\n<li>It offers a configurable localization through <code>localization.csv</code></li>\n<li>It offers a guided experience on-rails through <code>rails.csv</code></li>\n</ol>\n<h2>Preparation</h2>\n<ol>\n<li>First install the Python dependencies using:</li>\n</ol>\n<pre><code>pip3 install -r requirements.txt\n</code></pre>\n<ol start=\"2\">\n<li>Then update the <code>OpenAI</code>, <code>AstraDB</code> and optionally <code>LangSmith</code> secrets in <code>streamlit-langchain/.streamlit/secrets.toml</code>. There is an example provided at <code>secrets.toml.example</code>.</li>\n</ol>\n<h2>Customization</h2>\n<p>Now it's time to customize the app for your specific situation or customers.</p>\n<h3>Step 1</h3>\n<p>Define credentials by adding a new username and password in the <code>[passwords]</code> section in <code>streamlit-langchain/.streamlit/secrets.toml</code>.</p>\n<h3>Step 2</h3>\n<p>Define the UI language of the app by adding a localization code in the <code>[languages]</code> section in <code>streamlit-langchain/.streamlit/secrets.toml</code>. Currently <code>en_US</code> and <code>nl_NL</code> are supported. However it is easy to add additional languages in <code>localization.csv</code>.</p>\n<h3>Step 3</h3>\n<p>Create a guided experience by providing sample prompts in <code>rails.csv</code>. The convention here is that <code>&lt;username&gt;</code> from Step 1 is used to define the experience.</p>\n<h3>Step 4</h3>\n<p>Start up the app and pre-load relevant PDF and Text files so that the app has content that can be used as context for the questions/prompts in the next step. All this data will be loaded into a user specific table defined by <code>&lt;username&gt;</code>.</p>\n<h3>Step 5</h3>\n<p>Create a customized welcome page in the root folder. The convention here is to create a markdown file called <code>&lt;username&gt;.md</code>. Ideally, list which files have been pre-loaded.</p>\n<h2>Getting started</h2>\n<p>You're ready to run the app as follows:</p>\n<pre><code>streamlit run app.py\n</code></pre>\n<p>In addition to the pre-loaded content, a user can add additional content that will be used as context for prompts.</p>\n<h2>Deploy to the internet</h2>\n<p>It's easy to upload this app to the community edition of Streamlit. As the app uses a login page it is safe to have it publicly available.</p>\n<h2>Warning</h2>\n<p>The goal of this app is to be easily shared within enterprises. Just be aware that YOUR OPENAI subscription is being used for creating embeddings and LLM calls. This WILL incur cost.</p>\n",
    "readme_markdown": "# Configurable Enterprise Chat Agent\nThis Chat Agent is build specifically as a reusable and configurable sample app to share with enterprises or prospects. \n\n1. It uses [LangChain](https://www.langchain.com/) as the framework to easily set up LLM Q&A chains\n2. It uses [Streamlit](https://streamlit.io/) as the framework to easily create Web Applications\n3. It uses [Astra DB](https://astra.datastax.com/) as the Vector Store to enable Rerieval Augmented Generation in order to provide meaningfull contextual interactions\n4. It uses [Astra DB](https://astra.datastax.com/) as Short Term Memory to keep track of what was said and generated\n5. It uses a StreamingCallbackHandler to stream output to the screen which prevents having to wait for the final answer\n6. It allows for new Content to be uploaded, Vectorized and Stored into the Astra DB Vector Database so it can be used as Context\n7. It offers a configurable localization through `localization.csv`\n8. It offers a guided experience on-rails through `rails.csv`\n\n## Preparation\n1. First install the Python dependencies using:\n```\npip3 install -r requirements.txt\n```\n2. Then update the `OpenAI`, `AstraDB` and optionally `LangSmith` secrets in `streamlit-langchain/.streamlit/secrets.toml`. There is an example provided at `secrets.toml.example`.\n\n## Customization\nNow it's time to customize the app for your specific situation or customers.\n### Step 1\nDefine credentials by adding a new username and password in the `[passwords]` section in `streamlit-langchain/.streamlit/secrets.toml`.\n### Step 2\nDefine the UI language of the app by adding a localization code in the `[languages]` section in `streamlit-langchain/.streamlit/secrets.toml`. Currently `en_US` and `nl_NL` are supported. However it is easy to add additional languages in `localization.csv`.\n### Step 3\nCreate a guided experience by providing sample prompts in `rails.csv`. The convention here is that `<username>` from Step 1 is used to define the experience.\n### Step 4\nStart up the app and pre-load relevant PDF and Text files so that the app has content that can be used as context for the questions/prompts in the next step. All this data will be loaded into a user specific table defined by `<username>`.\n### Step 5\nCreate a customized welcome page in the root folder. The convention here is to create a markdown file called `<username>.md`. Ideally, list which files have been pre-loaded.\n\n## Getting started\nYou're ready to run the app as follows:\n```\nstreamlit run app.py\n```\nIn addition to the pre-loaded content, a user can add additional content that will be used as context for prompts.\n\n## Deploy to the internet\nIt's easy to upload this app to the community edition of Streamlit. As the app uses a login page it is safe to have it publicly available.\n\n## Warning\nThe goal of this app is to be easily shared within enterprises. Just be aware that YOUR OPENAI subscription is being used for creating embeddings and LLM calls. This WILL incur cost.",
    "_id": "qzg-streamlit-langchain"
}